"""Utilities for interacting with DCC applications.

This module intentionally keeps a very small public surface so that it can be
used in both the CLI application and by external tooling.  Only the features
needed by the tests are implemented which keeps the behaviour easy to reason
about.
"""

from __future__ import annotations

import json
import shutil
import subprocess
from collections.abc import Iterable
from enum import Enum
from pathlib import Path
from upath import UPath
from typing import Literal, TypeAlias

import logging

from libraries.aws.s5_sync import s5_sync

__all__ = ["SupportedDCC", "open_scene", "publish_scene"]


log = logging.getLogger(__name__)


class SupportedDCC(Enum):
    """Enumeration of DCC applications that OnePiece knows how to launch."""

    NUKE = "Nuke"
    MAYA = "Maya"
    BLENDER = "blender"
    HOUDINI = "houdini"
    MAX = "3dsmax"

    @property
    def command(self) -> str:
        """Return the executable name associated with the DCC."""

        return self.value


def _build_launch_command(dcc: SupportedDCC, path: Path) -> list[str]:
    """Return the command list that should be executed for *dcc*.

    ``Path`` objects are normalised to strings so that callers do not need to
    worry about the type of path they supply.  Only very small DCC specific
    differences are required so a plain lookup is sufficient.
    """

    if not isinstance(dcc, SupportedDCC):  # pragma: no cover - defensive.
        raise TypeError("dcc must be an instance of SupportedDCC")

    return [dcc.command, str(path)]


def open_scene(dcc: SupportedDCC, file_path: Path | str) -> None:
    """Open *file_path* inside the supplied *dcc*.

    The implementation purposefully avoids enforcing the existence of the file –
    doing so would complicate testing and prevent dry-run style usage.  The
    selected DCC determines the command that is executed and ``subprocess.run``
    is used with ``check=True`` so any failure from the external command is
    surfaced as a ``CalledProcessError``.
    """

    path = Path(file_path)
    command = _build_launch_command(dcc, path)
    subprocess.run(command, check=True)


def _copy_output(src: Path, dst: Path, *, treat_dst_as_dir: bool = False) -> list[Path]:
    """Copy ``src`` to ``dst`` and return the created files."""

    if src.is_dir():
        if dst.exists():
            shutil.rmtree(dst)
        shutil.copytree(src, dst)
        return [p for p in dst.rglob("*") if p.is_file()]

    target = dst
    if treat_dst_as_dir or (dst.exists() and dst.is_dir()):
        target = dst / src.name
    else:
        # If the destination does not exist we still want to honour the
        # directory intent when ``dst`` looks like a folder path.
        if dst.suffix == "":
            target = dst / src.name

    target.parent.mkdir(parents=True, exist_ok=True)
    shutil.copy2(src, target)
    return [target]


def _select_thumbnail(candidates: Iterable[Path]) -> Path | None:
    """Return the first plausible thumbnail candidate from ``candidates``."""

    thumbnail_exts = {".jpg", ".jpeg", ".png", ".exr", ".tif", ".tiff"}
    for candidate in candidates:
        if candidate.suffix.lower() in thumbnail_exts:
            return candidate
    return None


JSONPrimitive: TypeAlias = str | int | float | bool | None
JSONValue: TypeAlias = JSONPrimitive | dict[str, "JSONValue"] | list["JSONValue"]


def publish_scene(
    dcc: SupportedDCC,
    scene_name: str,
    renders: Path,
    previews: Path,
    otio: Path,
    metadata: dict[str, JSONValue],
    destination: Path,
    bucket: str,
    show_code: str,
    show_type: Literal["vfx", "prod"] = "vfx",
) -> UPath:
    """Package a scene's outputs locally and mirror them to S3.

    The packaging process is intentionally straightforward – the provided
    ``renders``, ``previews`` and ``otio`` paths are copied into a dedicated
    folder inside ``destination``.  ``metadata`` is serialised to
    ``metadata.json`` and a thumbnail is generated by copying the first image
    file discovered in the previews (falling back to renders).  Once the
    package is created it is synchronised to S3 using :func:`aws s3 sync` via
    :func:`libraries.libraries.aws.s3_sync.sync_to_bucket`.

    Returns the path to the created package which is convenient for testing
    and tooling.
    """

    package_dir = UPath(destination) / scene_name
    package_dir.mkdir(parents=True, exist_ok=True)

    renders_files = _copy_output(
        Path(renders), package_dir / "renders", treat_dst_as_dir=True
    )
    previews_files = _copy_output(
        Path(previews), package_dir / "previews", treat_dst_as_dir=True
    )
    _copy_output(Path(otio), package_dir / "otio", treat_dst_as_dir=True)

    metadata_path = package_dir / "metadata.json"
    metadata_path.write_text(json.dumps(metadata, indent=2, sort_keys=True))

    thumbnail_candidate = _select_thumbnail(previews_files or renders_files)
    if thumbnail_candidate:
        thumbs_dir = package_dir / "thumbnails"
        thumbs_dir.mkdir(exist_ok=True)
        shutil.copy2(thumbnail_candidate, thumbs_dir / thumbnail_candidate.name)

    log.info(
        "publish_scene_packaged dcc=%s package=%s bucket=%s show_code=%s show_type=%s",
        dcc.value,
        str(package_dir),
        bucket,
        show_code,
        show_type,
    )

    s5_sync(
        source=package_dir,
        target_bucket=bucket,
        context=scene_name,
        dry_run=False,
        include=None,
        exclude=None,
    )

    return package_dir
